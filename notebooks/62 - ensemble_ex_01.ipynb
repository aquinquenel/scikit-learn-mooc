{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Exercise M6.01\n",
    "\n",
    "The aim of this notebook is to investigate if we can tune the hyperparameters\n",
    "of a bagging regressor and evaluate the gain obtained.\n",
    "\n",
    "We will load the California housing dataset and split it into a training and\n",
    "a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BaggingRegressor` and provide a `DecisionTreeRegressor`\n",
    "to its parameter `base_estimator`. Train the regressor and evaluate its\n",
    "generalization performance on the testing set using the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic mean absolute error of the bagging regressor:\n",
      "36.27 k$\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "bagging = BaggingRegressor(base_estimator=tree, n_jobs=2)\n",
    "bagging.fit(data_train, target_train)\n",
    "target_predicted = bagging.predict(data_test)\n",
    "\n",
    "print(f\"Basic mean absolute error of the bagging regressor:\\n\"\n",
    "      f\"{mean_absolute_error(target_test, target_predicted):.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a `RandomizedSearchCV` instance using the previous model and\n",
    "tune the important parameters of the bagging regressor. Find the best\n",
    "parameters  and check if you are able to find a set of parameters that\n",
    "improve the default regressor still using the mean absolute error as a\n",
    "metric.\n",
    "\n",
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">You can list the bagging regressor's parameters using the <tt class=\"docutils literal\">get_params</tt>\n",
    "method.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_estimator__ccp_alpha\n",
      "base_estimator__criterion\n",
      "base_estimator__max_depth\n",
      "base_estimator__max_features\n",
      "base_estimator__max_leaf_nodes\n",
      "base_estimator__min_impurity_decrease\n",
      "base_estimator__min_samples_leaf\n",
      "base_estimator__min_samples_split\n",
      "base_estimator__min_weight_fraction_leaf\n",
      "base_estimator__random_state\n",
      "base_estimator__splitter\n",
      "base_estimator\n",
      "bootstrap\n",
      "bootstrap_features\n",
      "max_features\n",
      "max_samples\n",
      "n_estimators\n",
      "n_jobs\n",
      "oob_score\n",
      "random_state\n",
      "verbose\n",
      "warm_start\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "for param in bagging.get_params().keys():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a90d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": randint(10, 30),\n",
    "    \"max_samples\": [0.5, 0.8, 1.0],\n",
    "    \"max_features\": [0.5, 0.8, 1.0],\n",
    "    \"base_estimator__max_depth\": randint(3, 10),\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    bagging, param_grid, n_iter=20, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "_ = search.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434e5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_base_estimator__max_depth</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>39.094171</td>\n",
       "      <td>1.354637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9</td>\n",
       "      <td>39.522652</td>\n",
       "      <td>1.231544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>39.582679</td>\n",
       "      <td>1.074849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>40.406350</td>\n",
       "      <td>1.801861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>41.032901</td>\n",
       "      <td>1.306976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>41.272820</td>\n",
       "      <td>1.141825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>42.801115</td>\n",
       "      <td>1.159104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>43.113344</td>\n",
       "      <td>1.035623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>43.731486</td>\n",
       "      <td>1.016436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>43.911184</td>\n",
       "      <td>1.410504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>44.076880</td>\n",
       "      <td>1.009755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9</td>\n",
       "      <td>47.023528</td>\n",
       "      <td>1.969721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>48.532827</td>\n",
       "      <td>1.098628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>48.566996</td>\n",
       "      <td>1.075088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>48.724744</td>\n",
       "      <td>0.713260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>48.846683</td>\n",
       "      <td>0.901947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>50.127809</td>\n",
       "      <td>1.347653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>53.453344</td>\n",
       "      <td>3.300100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>57.573546</td>\n",
       "      <td>0.797369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>62.485139</td>\n",
       "      <td>3.422301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_samples param_max_features  \\\n",
       "13                 26               1.0                1.0   \n",
       "0                  22               1.0                0.8   \n",
       "6                  14               0.8                1.0   \n",
       "17                 12               0.8                0.8   \n",
       "2                  29               0.5                0.8   \n",
       "19                 17               0.5                1.0   \n",
       "4                  18               0.8                1.0   \n",
       "10                 12               0.5                1.0   \n",
       "1                  12               1.0                1.0   \n",
       "7                  10               0.8                0.8   \n",
       "11                 27               1.0                0.5   \n",
       "12                 14               0.5                0.5   \n",
       "14                 10               1.0                1.0   \n",
       "9                  19               0.8                0.5   \n",
       "18                 17               1.0                0.8   \n",
       "16                 20               1.0                0.8   \n",
       "3                  16               0.5                0.5   \n",
       "15                 10               0.8                0.5   \n",
       "8                  13               1.0                0.8   \n",
       "5                  10               1.0                0.5   \n",
       "\n",
       "   param_base_estimator__max_depth  mean_test_error  std_test_error  \n",
       "13                               9        39.094171        1.354637  \n",
       "0                                9        39.522652        1.231544  \n",
       "6                                9        39.582679        1.074849  \n",
       "17                               8        40.406350        1.801861  \n",
       "2                                8        41.032901        1.306976  \n",
       "19                               8        41.272820        1.141825  \n",
       "4                                7        42.801115        1.159104  \n",
       "10                               7        43.113344        1.035623  \n",
       "1                                7        43.731486        1.016436  \n",
       "7                                7        43.911184        1.410504  \n",
       "11                               9        44.076880        1.009755  \n",
       "12                               9        47.023528        1.969721  \n",
       "14                               5        48.532827        1.098628  \n",
       "9                                6        48.566996        1.075088  \n",
       "18                               5        48.724744        0.713260  \n",
       "16                               5        48.846683        0.901947  \n",
       "3                                6        50.127809        1.347653  \n",
       "15                               5        53.453344        3.300100  \n",
       "8                                3        57.573546        0.797369  \n",
       "5                                3        62.485139        3.422301  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_grid.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"mean_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ee7c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error after tuning of the bagging regressor:\n",
      "38.88 k$\n"
     ]
    }
   ],
   "source": [
    "target_predicted = search.predict(data_test)\n",
    "print(f\"Mean absolute error after tuning of the bagging regressor:\\n\"\n",
    "      f\"{mean_absolute_error(target_test, target_predicted):.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the predictor provided by the bagging regressor does not need\n",
    "much hyperparameter tuning compared to a single decision tree."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
